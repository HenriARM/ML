{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNetGPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSsU7LkHk2TP3QyCwQdBHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriARM/ML/blob/master/ResNetGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eqQdzB90iz1",
        "outputId": "804e2e47-1391-40b6-c9d4-b8b466bd0a25"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbs-bBcK2Xus",
        "outputId": "3c7cda81-c955-4f23-9013-4ea88863d3f5"
      },
      "source": [
        "%pip install torchnet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchnet\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/b2/d7f70a85d3f6b0365517782632f150e3bbc2fb8e998cd69e27deba599aae/torchnet-0.0.4.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchnet) (1.7.0+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet) (1.15.0)\n",
            "Collecting visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchnet) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchnet) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchnet) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchnet) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (22.0.2)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (7.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (2020.12.5)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: torchnet, visdom, torchfile\n",
            "  Building wheel for torchnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchnet: filename=torchnet-0.0.4-cp36-none-any.whl size=29744 sha256=b2b3c97dab98bbb57d633b3209fcb1f6b0c78b0099caee9c32d2537c70edd260\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/03/fb/1c212c2f20905cdf97fe39022946cf16b8e66ed754a6663400\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655252 sha256=51d813880fa3c18d61db808a5fbb1768b237655d55bf2f7a68c50ec944669511\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5713 sha256=341b578e572573869c1478b28d86f31e7ea61b24ed921d4b0ddc09afda33956c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built torchnet visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom, torchnet\n",
            "Successfully installed jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 torchnet-0.0.4 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vxB7qe92TKd"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import pad, softmax\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torchnet.meter import AverageValueMeter"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2kYu8-22n8L"
      },
      "source": [
        "DEVICE = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "lr = 1e-4"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nvChcI462p7E",
        "outputId": "c6cebe4f-7d36-4580-c93b-e4be58788500"
      },
      "source": [
        "DEVICE"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHO6zjpR2szt"
      },
      "source": [
        "def conv_3x3(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(num_features=out_channels)\n",
        "    )\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.layers = nn.Sequential(\n",
        "            conv_3x3(in_channels=self.in_channels, out_channels=self.out_channels),\n",
        "            nn.ReLU(),\n",
        "            conv_3x3(in_channels=self.out_channels, out_channels=self.out_channels)\n",
        "        )\n",
        "        self.shortcut = conv_3x3(in_channels=self.in_channels, out_channels=self.out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        x = self.layers(x)\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class ResidualGate(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, blocks):\n",
        "        super(ResidualGate, self).__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            ResidualBlock(in_channels=in_channels, out_channels=out_channels),\n",
        "            *[ResidualBlock(in_channels=out_channels, out_channels=out_channels) for _ in range(blocks - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block.forward(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.input = nn.Sequential(\n",
        "            # out = (28 + 2*1 - 3) / 1 + 1   (28)\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            # out = (28 + 2*1 - 3) / 2 + 1   (14)\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        size = [16, 32, 64, 128]\n",
        "        self.gates = nn.ModuleList(\n",
        "            [ResidualGate(in_channels=i[0], out_channels=i[1], blocks=2) for i in tuple(zip(size, size[1:]))]\n",
        "        )\n",
        "        self.fc = nn.Linear(in_features=128, out_features=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input(x)\n",
        "        for gate in self.gates:\n",
        "            x = gate.forward(x)\n",
        "        x = torch.nn.functional.adaptive_avg_pool2d(x, output_size=(1, 1))\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Use standard FashionMNIST dataset\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./datasets',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "    test_set = torchvision.datasets.FashionMNIST(\n",
        "        root='./datasets',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor()])\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    model = ResNet(in_channels=1, n_classes=10)\n",
        "    model.to(DEVICE)\n",
        "    # summary(model, (1, 28, 28))\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    meters: dict = {\n",
        "        'train_loss': [],\n",
        "        'test_loss': []\n",
        "    }\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(\"\\nepoch = \", epoch)\n",
        "        for loader in [train_loader, test_loader]:\n",
        "            if loader == train_loader:\n",
        "                print(\"\\n\\ttraining:\")\n",
        "                meter_prefix = \"train\"\n",
        "                model = model.train()\n",
        "                torch.set_grad_enabled(True)\n",
        "            else:\n",
        "                print(\"\\n\\ttesting:\")\n",
        "                meter_prefix = \"test\"\n",
        "                model = model.eval()\n",
        "                torch.set_grad_enabled(False)\n",
        "            losses = AverageValueMeter()\n",
        "            for x, y_idx in loader:\n",
        "                # if losses.n > 10:\n",
        "                #     break\n",
        "\n",
        "                x = x.to(DEVICE)\n",
        "                y_idx = y_idx.to(DEVICE)\n",
        "                y_prim = model.forward(x)\n",
        "\n",
        "                # use custom implemented cross-entropy      \n",
        "                # loss = -torch.mean(torch.log(y_prim + 1e-8)[torch.arange(BATCH_SIZE), y_idx])\n",
        "                # print(loss)\n",
        "\n",
        "                # convert label to one-hot encoded\n",
        "                y = torch.zeros((x.size(0), 10))\n",
        "                y[torch.arange(x.size(0)), y_idx] = 1.0\n",
        "                y = y.to(DEVICE)\n",
        "\n",
        "                # batch loss\n",
        "                loss = -torch.mean(y * torch.log(y_prim + 1e-8))\n",
        "\n",
        "                # loss.to('cpu').item() => single scalar value\n",
        "                # loss.to('cpu').data.numpy() => matrix\n",
        "                losses.add(loss.to(DEVICE).item())\n",
        "\n",
        "                if loader == train_loader:\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "            # losses.value is average loss of all batches\n",
        "            meters[f'{meter_prefix}_loss'].append(losses.value()[0])\n",
        "            print(losses.value()[0])\n",
        "    print(meters)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0F9_aL82zTb",
        "outputId": "8cc3baf2-ed5f-428d-a92b-6ec007cecb69"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print(DEVICE)\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      main()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "\n",
            "epoch =  0\n",
            "\n",
            "\ttraining:\n",
            "0.04847013528571968\n",
            "\n",
            "\ttesting:\n",
            "0.033804590226548484\n",
            "\n",
            "epoch =  1\n",
            "\n",
            "\ttraining:\n",
            "0.02919201808832664\n",
            "\n",
            "\ttesting:\n",
            "0.029807117530352378\n",
            "\n",
            "epoch =  2\n",
            "\n",
            "\ttraining:\n",
            "0.02444483154390786\n",
            "\n",
            "\ttesting:\n",
            "0.026959021670660784\n",
            "\n",
            "epoch =  3\n",
            "\n",
            "\ttraining:\n",
            "0.020589374094657397\n",
            "\n",
            "\ttesting:\n",
            "0.025049498636916183\n",
            "\n",
            "epoch =  4\n",
            "\n",
            "\ttraining:\n",
            "0.01743116132867363\n",
            "\n",
            "\ttesting:\n",
            "0.028677609793628288\n",
            "\n",
            "epoch =  5\n",
            "\n",
            "\ttraining:\n",
            "0.01468802342858555\n",
            "\n",
            "\ttesting:\n",
            "0.02667188205441851\n",
            "\n",
            "epoch =  6\n",
            "\n",
            "\ttraining:\n",
            "0.012274360920397886\n",
            "\n",
            "\ttesting:\n",
            "0.028266032798820808\n",
            "\n",
            "epoch =  7\n",
            "\n",
            "\ttraining:\n",
            "0.009898733621937803\n",
            "\n",
            "\ttesting:\n",
            "0.028449030158519274\n",
            "\n",
            "epoch =  8\n",
            "\n",
            "\ttraining:\n",
            "0.008322510416612021\n",
            "\n",
            "\ttesting:\n",
            "0.02906098164570559\n",
            "\n",
            "epoch =  9\n",
            "\n",
            "\ttraining:\n",
            "0.006783474998607957\n",
            "\n",
            "\ttesting:\n",
            "0.03236117986902879\n",
            "{'train_loss': [0.04847013528571968, 0.02919201808832664, 0.02444483154390786, 0.020589374094657397, 0.01743116132867363, 0.01468802342858555, 0.012274360920397886, 0.009898733621937803, 0.008322510416612021, 0.006783474998607957], 'test_loss': [0.033804590226548484, 0.029807117530352378, 0.026959021670660784, 0.025049498636916183, 0.028677609793628288, 0.02667188205441851, 0.028266032798820808, 0.028449030158519274, 0.02906098164570559, 0.03236117986902879]}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}