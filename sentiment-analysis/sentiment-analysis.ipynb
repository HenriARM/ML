{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPo+ARmpLE7o/vuuxZf+5/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriARM/ML/blob/master/sentiment-analysis/sentiment-analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOFgXeM3zU7C",
        "colab_type": "text"
      },
      "source": [
        "Sentiment Analysis of clothes reviews using Word2Vec and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb7RntaeKHIj",
        "colab_type": "code",
        "outputId": "368347fd-9aed-4141-9593-225f0b5e9a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Andj7FRcLhnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data fetching\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/sentiment-analysis/reviews.csv', delimiter=',', encoding='latin-1').dropna() # drop empty ones \n",
        "reviews = np.array(data[\"Review Text\"])\n",
        "recommendations = np.array(data[\"Recommended IND\"])\n",
        "ratings = np.array(data[\"Rating\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oWrmmTIiMhq",
        "colab_type": "code",
        "outputId": "ba24250b-95f0-4894-85b9-f3b2f5aa6db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Data Processing\n",
        "from string import punctuation\n",
        "\n",
        "# convert to lower case and remove punctuation\n",
        "f_clean = np.vectorize(lambda t: ''.join([c for c in t.lower() if c not in punctuation]))\n",
        "reviews = f_clean(reviews)\n",
        "print(reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i had such high hopes for this dress and really wanted it to work for me i initially ordered the petite small my usual size but i found this to be outrageously small so small in fact that i could not zip it up i reordered it in petite medium which was just ok overall the top half was comfortable and fit nicely but the bottom half had a very tight under layer and several somewhat cheap net over layers imo a major design flaw was the net over layer sewn directly into the zipper  it c'\n",
            " 'i love love love this jumpsuit its fun flirty and fabulous every time i wear it i get nothing but great compliments'\n",
            " 'this shirt is very flattering to all due to the adjustable front tie it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan love this shirt'\n",
            " ...\n",
            " 'got this in the petite xs in mint the color is gorgeous its a really bright mint that complements my super fair skin really well though it would work for pretty much any skin tone its still a good length in the petite for the type of shirt it is 51 and hits right around my lower hips it is a thinner fabric but thats what i was expecting and the lace detailing at the bottom of the sleeves is a nice touch and makes it more than just a plain henley'\n",
            " 'beautiful unique design its very flattering the way the fabric hangs\\n\\ni usually wear a 10 but because the lining is much smaller than the dress which many linings are its a pet peeve of mine i sized up to a 12 and took in the shoulders a couple inches so the bodice area would sit correctly on my bust otherwise in the 10 my stomach would feel squeezed even if it looked like it fit perfectly that said im very sensitive to that kind of thing\\n\\nother reviewers have noted that the emb'\n",
            " 'i love a jumpsuit for its ease of dressing this is the 3rd ive purchased from retailer\\nmaterial is thin and gauzy as described with a sweater or jacket it will be plenty warm for so cal winters and great the rest of the year\\nif you are all tall the waist might fall a bit short i am 56 and the waist just barely hits my waistline\\ndoubt i would have purchased this item full price but on sale its a great deal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hggh9HVYrcIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "review_lines = list()\n",
        "\n",
        "word_sentences = list()\n",
        "for review in reviews:\n",
        "  review = review.split()\n",
        "  word_sentences.append([word for word in review if word.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inwi3aqZQ7QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "\n",
        "model = gensim.models.Word2Vec(sentences=word_sentences, window=5, workers=4, min_count=1, size=64)\n",
        "words = list(model.wv.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY338us0vYvY",
        "colab_type": "code",
        "outputId": "8f6e94db-021d-485f-b26b-b4df0375bd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Test Word2Vec\n",
        "model.wv.most_similar(\"terrible\")\n",
        "model.wv.most_similar(positive=['orange', 'water'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('heather', 0.8220078945159912),\n",
              " ('rust', 0.8116054534912109),\n",
              " ('burgundy', 0.8107340335845947),\n",
              " ('beige', 0.8016921877861023),\n",
              " ('poppy', 0.7991843223571777),\n",
              " ('mauve', 0.79749596118927),\n",
              " ('background', 0.7955273389816284),\n",
              " ('peach', 0.7941948771476746),\n",
              " ('faded', 0.7933332920074463),\n",
              " ('royal', 0.7912448048591614)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxoTHCLnxDvJ",
        "colab_type": "code",
        "outputId": "13b72535-6c1f-402c-ab50-db19c2c4e58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# TODO: add save word2wec dictionart\n",
        "# model[\"orange\"].size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYnr-VYCzJVC",
        "colab_type": "code",
        "outputId": "b7d45ec9-5729-4bf9-9eea-fb8b9f3261de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(word_sentences)\n",
        "sequences = tokenizer_obj.texts_to_sequences(word_sentences)\n",
        "\n",
        "word_index = tokenizer_obj.word_index\n",
        "print(len(word_index))\n",
        "review_pad = pad_sequences(sequences, maxlen=300)\n",
        "sentiment = recommendations\n",
        "print(sentiment.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17103\n",
            "(19252,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfIWvWzp3mlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, 64))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  if i > num_words:\n",
        "    continue\n",
        "  embedding_vector = word_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    #words not found = 0000000\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6mGwCJt5CHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "\n",
        "#model here\n",
        "#TODO change\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(\n",
        "    num_words,\n",
        "    64,\n",
        "    embeddings_initializer=Constant(embedding_matrix),\n",
        "    input_length=max_length,\n",
        "    trainable=False\n",
        ")\n",
        "model.add(embedding_layer)\n",
        "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsB6nRv29_bR",
        "colab_type": "code",
        "outputId": "3825e8ab-c90e-4b93-bb3e-74923d9f57fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(review_pad, recommendations, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ei2JGsE9w9W",
        "colab_type": "code",
        "outputId": "1211b28e-b530-44ca-a6bb-597771aafc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1, batch_size=50, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "15401/15401 [==============================] - 66s 4ms/step - loss: 0.4721 - acc: 0.8182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a19d25940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    }
  ]
}