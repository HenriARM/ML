{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive-bayes-iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQY8r8Fs25e3n/xPonPP0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriARM/ML/blob/master/naive-bayes/naive-bayes-iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpYGDz9xIVmL",
        "colab_type": "text"
      },
      "source": [
        "Using [Gaussian naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) for [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBjOHQAaoKbw",
        "colab_type": "text"
      },
      "source": [
        "# **Problem**\n",
        "Given an object to be classified, represented by a vector $x = (x_1 \\dots x_n) $ with n independent features, for each of $K$ possible classes $C_k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aP0_st9TyQn",
        "colab_type": "text"
      },
      "source": [
        "# **Bayes probability model**\n",
        "\n",
        "[Bayes theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem): $ p(C_k \\mid x) = \\frac{p(C_k) p(x \\mid C_k)}{p(x)}$\n",
        "\n",
        "The denominator of fraction does not depend on $C_k$ that's why $p(x)$ is constant and we won't use it.\n",
        "\n",
        "The numerator is equivalent to the joint probability:\n",
        "$p(C_k, x_1, \\dots, x_n)$ = $p(x_1 \\mid x_2, \\dots, x_n, C_k)$ $p(x_2 \\mid x_3, \\dots, x_n, C_k)$ $\\dots$ $p(x_{n-1} \\mid x_n, C_k)$ $p(x_n \\mid C_k)$ $p(C_k)$\n",
        "\n",
        "We assume that all features in $x$ are mutually independent:\n",
        "$p(x_i \\mid x_{i+1} \\dots x_n, C_k) = p(x_i \\mid C_k) $\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-RQccnnpAMU",
        "colab_type": "text"
      },
      "source": [
        "# **Naive Bayes classifier**\n",
        "The naive Bayes classifier combines Bayes probability model with a decision rule.\n",
        "\n",
        "$y = \\underset{k \\in \\{1, \\dots, K\\}}{argmax} [p(C_k)\\Pi_{i=1}^{n}p(x_i \\mid C_k)]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB2Gf0KjqPYy",
        "colab_type": "text"
      },
      "source": [
        "# **Gaussian naive Bayes**\n",
        "\n",
        "Uses [Gaussian](https://en.wikipedia.org/wiki/Normal_distribution) (normal) distribution when dealing with continuous data: \n",
        " $ p(x \\mid C_k)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {x-\\mu }{\\sigma }}\\right)^{2}} $ \n",
        "\n",
        "$\\mu = \\frac{1}{n} \\sum_{i = 1}^{n} {x_i} $ (mean)\n",
        "\n",
        "$\\sigma = \\sqrt{ \\frac{1}{n} \\sum_{i = 1}^{n} {(x_i - \\bar{x})^2} }$ (standard deviation) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-p132rcg7V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt, pi, exp\n",
        "\n",
        "\"\"\" Math class with static methods used for working with arrays \"\"\"\n",
        "class Math:\n",
        "  \n",
        "  \"\"\" Mean \n",
        "  Args:\n",
        "    x: iterable object\n",
        "  Returns:\n",
        "    <class 'float'>\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def mean(x):\n",
        "    return sum(x)/len(x)\n",
        "\n",
        "  \"\"\" Standard deviation \n",
        "  Args:\n",
        "    x: iterable object, shape (n)\n",
        "    mean: mean of x\n",
        "  Returns:\n",
        "    <class 'float'>\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def stdev(x, mean):\n",
        "    return sqrt( (1/len(x)) * sum([(x_i - mean)**2 for x_i in x]) )\n",
        "  \n",
        "  \"\"\" Gaussian (Normal) distribution\n",
        "  Args:\n",
        "    x: iterable object shape (n)\n",
        "    mean: mean of x\n",
        "    stdev: standard deviation of x\n",
        "  Returns:\n",
        "    <class 'float'>\n",
        "  \"\"\"\n",
        "  @staticmethod\n",
        "  def normal_distribution(x, mean, stdev):\n",
        "    exponent = exp( -1/2 * ( ( ( x - mean ) / stdev )**2 ) )\n",
        "    return ( 1 / ( stdev * sqrt(2 * pi) ) ) * exponent\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hftecoE6x0Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Gaussian naive Bayes classifier \"\"\"\n",
        "class GaussianNB:\n",
        "\tdef __init__(self):\n",
        "\t\tself.class_amount = 0\n",
        "\t\tself.feauture_amount = 0\n",
        "\t\tself.data_amount = 0\n",
        "\t\t# dictionary with separated vectors by their class\n",
        "\t\tself.separated = None\n",
        "\t\t# dictionary, which stores stdev and mean for each feauture in class used for normal distribution (P(x_i|C_k)), x_i - vector dimension, C_k - class\n",
        "\t\tself.features = None\n",
        "\n",
        "\t\"\"\" Separates training data vectors by their classes\n",
        "  Args:\n",
        "    x: iterable object of classified vectors, shape (n_samples, n_features)\n",
        "\t\ty: iterable object of vector classes, shape (n_samples, 1)\n",
        "  Returns:\n",
        "\t Dictionary wiht list of vectors indexed by class\n",
        "  \"\"\"\n",
        "\tdef __separate_data_by_class(self, x, y):\n",
        "\t\td = dict()\n",
        "\t\tfor i in range(len(x)):\n",
        "\t\t\tvector = x[i]\n",
        "\t\t\tvclass = y[i]\n",
        "\t\t\t# create new list for vector class if didn't exist before\n",
        "\t\t\tif (vclass not in d):\n",
        "\t\t\t\td[vclass] = list()\n",
        "\t  \t# append object to the class\n",
        "\t\t\td[vclass].append(vector)\n",
        "\t\treturn d\n",
        "\n",
        "\t\"\"\" Fit Gaussian Naive Bayes according to X, y\n",
        "  Args:\n",
        "    x: iterable object of classified vectors, shape (n_samples, n_features)\n",
        "\t\ty: iterable object of vector classes, shape (n_samples, 1)\n",
        "  \"\"\"\n",
        "\tdef fit(self, x, y):\n",
        "\t\tself.data_amount, self.feature_amount  = x.shape\n",
        "\t\tself.separated = self.__separate_data_by_class(x,y)\n",
        "\t\tself.class_amount = len(self.separated)\n",
        "\t\t# get stdev and mean for each feature in class\n",
        "\t\tself.features = dict()\n",
        "\t\tfor k in range(self.class_amount):\n",
        "\t\t\tself.features[k] = list()\n",
        "\t\t\tfor i in range(self.feature_amount):\n",
        "\t\t\t\tcolumn = np.array(self.separated[k])[:,i]\n",
        "\t\t\t\tm = Math.mean(column)\n",
        "\t\t\t\tsd = Math.stdev(column, m)\n",
        "\t\t\t\tself.features[k].append((m, sd))\n",
        "\t\tprint(type(self.separated))\n",
        "\n",
        "\t\"\"\" Calculate the probabilities\n",
        "  Args:\n",
        "    x_test: vector to predict\n",
        "  Returns:\n",
        "\t index of class\n",
        "  \"\"\"\n",
        "\tdef predict(self, x_test):\n",
        "\t\tprobabilities = dict()\n",
        "\t\tfor k in range(self.class_amount):\n",
        "\t\t\t# Calculate p(C_K), amount of vectors with C_k class divided by amount of all train vectors\n",
        "\t\t\tp_c_k = len(self.separated[k]) / self.data_amount\n",
        "\t\t\tprobabilities[k] = p_c_k\n",
        "\t\t\tfor i in range(self.feature_amount):\n",
        "\t\t\t\tm, sd = self.features[k][i]\n",
        "\t\t\t\treiz = Math.normal_distribution(x_test[i], m, sd)\n",
        "\t\t\t\tprobabilities[k] *= reiz\n",
        "\n",
        "\t\tprint(\"Probabilities:\", probabilities)\n",
        "\t\t# Find class with highest probability\n",
        "\t\tarr = np.array(list(probabilities.values()))\n",
        "\t\ty = arr.argmax(axis = 0)\n",
        "\t\treturn y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXFBJ-AaJ-rJ",
        "colab_type": "code",
        "outputId": "102abd57-78cb-4de7-82f5-1f0b533a12fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "# Iris dataset is available in scikit\n",
        "from sklearn.datasets import load_iris\n",
        " \n",
        "x_train, y_train = load_iris(return_X_y = True)\n",
        "classes = load_iris().target_names\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "x_test = np.array(x_train[49])\n",
        "class_index = classifier.predict(x_test)\n",
        "print(\"Flower types: \", classes)\n",
        "flower_name = classes[class_index]\n",
        "print(\"The flower with features: %s is %s\" %(x_test, flower_name))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "Probabilities: {0: 2.8835592775381644, 1: 1.0328680590068721e-17, 2: 3.2212082936497125e-25}\n",
            "Flower types:  ['setosa' 'versicolor' 'virginica']\n",
            "The flower with features: [5.  3.3 1.4 0.2] is setosa\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}